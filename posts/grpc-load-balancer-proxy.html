<html>

<head>
  <title>gRPC Load balancing | Tam's Blog</title>
  <meta charset="utf-8">
  <meta http-equiv="content-type" content="text/html;">
  <meta name=viewport content="initial-scale=1.0 maximum-scale=1.0">
  <meta property='og:image' content='https://melancholy.com/img/default.jpg'>
  <link rel="apple-touch-icon" sizes="180x180" href="../apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
  <link rel="manifest" href="../manifest.json">
  <link rel="mask-icon" href="../safari-pinned-tab.svg" color="#5bbad5">
  <meta name="theme-color" content="#ffffff">
  <link href="https://fonts.googleapis.com/css?family=Inconsolata:400,700&amp;subset=latin-ext,vietnamese"
    rel="stylesheet">
  <!-- <link href="../css/theme.css?t=" rel="stylesheet" type="text/css"> -->
  <link href="/css/theme.css" rel="stylesheet" type="text/css">
  <!-- <link href="/css/gruvbox-dark.css" rel="stylesheet" type="text/css"> -->
  <link rel="stylesheet" href="../css/highlight/tomorrow.css">
  <link rel="stylesheet" href="../css/fontello.css">
  <link rel="stylesheet" href="../emoji/css/emoji.dist.css">
  <link rel="stylesheet" href="../emoji/css/emojione.min.css">
  <link rel="stylesheet" href="../emoji/css/messenger.min.css">
  <link rel="stylesheet" href="../emoji/css/thinking.ext.css">
  <!-- <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/default.min.css"> -->
  <script src="../js/highlight.min.js"></script>
  <script src="../js/autosizing.js"></script>
  <script src="../js/fetch.js"></script>
  <script>
    hljs.initHighlightingOnLoad();
    hljs.highlightAll();
  </script>
</head>

<body>
  <div class="header">
    <a href="/"><span class="avatar"></span><span class="header-link">Tam's Blog</span></a>
  </div>
  <div class="container">
    <div class="main">
      <p><a href="/">&lt;- Quay về trang chủ</a></p>
      <h1>gRPC Load balancing</h1>
      <p>Khi thị trường có xu hướng chuyển dần từ monolithic sang microservice, bài toán giao tiếp giữa các service trở nên rất quan trọng, với những service thông thường hiện nay, mình thấy có 3 cách giao tiếp chính:</p>
<ul>
<li>HTTP APIs</li>
<li>gRPC</li>
<li>Message queue</li>
</ul>
<p>Khi triển khai hệ thống cần xử lý một lượng tải lớn, mỗi loại service sẽ cần phải chạy rất nhiều instance, vậy bài toán đặt ra làm thế nào để chia tải giữa các instance? Độ hiệu quả cũng như chi phí cài đặt, bảo trì như thế nào? Phương pháp áp dụng cho mỗi protocol có khác nhau không?</p>
<p>Để trả lời những câu hỏi trên, mình sẽ viết một chuỗi bài tìm hiểu về các phương pháp load balacing cho gRPC protocol.</p>
<h2><a href="#phương-pháp" aria-hidden="true" class="anchor" id="phương-pháp"></a>Phương pháp</h2>
<p>Hiện tại có một vài phương pháp phổ biến để xử lý grPC load balancing:</p>
<ul>
<li><strong>Proxy load balancing</strong>: là phương pháp truyền thống, LB sẽ đóng vai trò như một reverse proxy, HAProxy, Nginx, LB của cloud provider,... là các ví dụ.</li>
<li><strong>Client side load balancing</strong>: phía client chủ động quản lý connection cũng như cơ chế load balancing, có thể tự custom hoàn toàn dựa trên các specification của gRPC hoặc kết hợp với ZooKeeper/Etcd/Consul,...</li>
<li><strong>Look-aside load balancing</strong>: có một external load balancing component chịu trách nhiệm quản lý các servers (service discovery) và trả lời thông tin cho client mỗi khi được yêu cầu.</li>
<li><strong>Service mesh</strong>: sử dụng các load balancer có sẵn trong các proxy như Istio, Envoy,...</li>
</ul>
<p>Mỗi phương pháp sẽ có ưu nhược điểm riêng cũng như chi phí cài đặt, bảo trì khác nhau.</p>
<h2><a href="#grpc-load-balancing" aria-hidden="true" class="anchor" id="grpc-load-balancing"></a>gRPC load balancing</h2>
<p>Trước tiên, hãy cùng mình phân tích một vài lưu ý về gRPC load balancing. Có phải chỉ cần sử dụng load balancer trước cụm backend servers thì mọi chuyện được giải quyết?</p>
<p>gRPC là giao thức sử dụng <code>HTTP/2</code>, có cơ chế multiplex nhiều request/response dựa trên cùng 1 connection, vì tính chất này, tcp connection được sử dụng bởi grpc sẽ có tính chất <code>long-lived</code>, khác với HTTP APIs dựa trên <code>HTTP/1.1</code>.</p>
<p><img src="img/grpc-connection-load-balancing.png" alt="grpc-connection-load-balancing" /></p>
<p>Với ý nghĩ đơn giản nhất, chúng ta sẽ tạo 1 connection đến LB và sử dụng nó để gửi tất cả requests. Tuy nhiên, vấn đề xuất hiện vì tính chất <code>long-lived</code> này, khi LB tạo connection tới một backend server, tất cả những requests sau đó sẽ được gửi đến <code>server instance 1</code>, 2 servers còn lại sẽ ngồi chơi. Khi tạo mới một connection khác, tuỳ vào thuật toán <code>load balancing</code> ở LB, connection mới có thể sẽ tới <code>server instance 2</code> hoặc <code>server instance 3</code>. Vậy bạn có thể thấy, dù cho LB load balance ở <code>layer 4</code> hay <code>layer 7</code> thì kiểu load balancing này là <code>connection-based load balancing</code>.</p>
<p>Để giải quyết vấn đề này, chúng ta sẽ sử dụng kĩ thuật <code>pooling</code> ở phía client, mục đích là tạo nhiều connections thông qua LB và sử dụng chúng để gửi request. Ở kĩ thuật này, LB sẽ thực hiện chia tải trên <code>connection level</code>, client sẽ thực hiện chia tải trên <code>request level</code>. Chi phí để hiện thực client sẽ cao hơn vì chúng ta cần quản lý pool cũng như chọn connection để gửi request.</p>
<p><img src="img/grpc-loadbalacning-requests.png" alt="grpc-loadbalacning-requests" /></p>
<p><em><strong>Điều gì sẽ xảy ra khi scale server?</strong></em></p>
<p>Khi một server mới được thêm vào cụm backend, nếu pool ở client của chúng ta đã đạt đến số connection tối đa thì cách làm này gặp vấn đề lớn, sẽ không có connection mới nào được khởi tạo đến server mới và dẫn đến sự quá tải ở các server đang có, dẫn đến sập server nếu số lượng request tăng. Để giải quyết vấn đề này, chúng ta cần có cơ chế refresh pool, mỗi connection trong pool sẽ có 1 thời gian sống nhất định, client sẽ chạy 1 job để refresh pool theo cơ chế như:</p>
<ul>
<li>Đóng những connection đã hết thời gian sống.</li>
<li>Đóng những connection bị lỗi.</li>
<li>Khởi tạo connection mới thông qua LB.</li>
</ul>
<p>Điều này đảm bảo connection sẽ được chia tải đều đến các server, tuy nhiên chúng ta cần tính toán kĩ những số liệu trên dựa trên đặc điểm chịu tải của từng service, việc này có thể được làm thông qua quá trình <code>benchmark</code> hệ thống.</p>
<p><em><strong>Loại bỏ load balancer</strong></em></p>
<p>Đối với những hệ thống yêu cầu khắt khe về hiệu năng, sử dụng load balancer có lẽ không phải là giải pháp tốt. Client có một lợi thế khi sử dụng load balancer là nó không cần phải quan tâm đến địa chỉ IP cụ thể của backend hay những thứ khác liên quan đến hạ tầng, tất cả những thứ nó cần phải biết là địa chỉ của load balancer, nếu chúng ta không sử dụng load balancer, một vấn đề mới xuất hiện, <strong>làm thế nào để client và server tìm thấy nhau?</strong></p>
<p>Đây là câu hỏi kinh điển gắn liền với thuật ngữ <code>service discovery</code>, có một service thứ 3 đứng ra làm cầu nối giữa client và server, service này lưu thông tin của server và trả lời mỗi khi client hỏi hoặc chủ động thông báo mỗi khi có sự thay đổi. Khi client có được địa chỉ của các server thông qua service thứ 3 này, nó sẽ khởi tạo connection trực tiếp đến các server và <strong>chia tải request</strong> trên các connection này, việc load balancing đã trở thành <code>application load balacing</code> bởi vì chúng ta đang thao tác trên request.</p>
<p><img src="img/grpc-service-discovery.png" alt="grpc-service-discovery" /></p>
<p>Để tăng hiệu năng cũng như throughput về mặt số lượng request, chúng ta cũng có thể áp dụng kĩ thuật pooling ở phía client cho phương pháp này.</p>
<h2><a href="#tổng-kết" aria-hidden="true" class="anchor" id="tổng-kết"></a>Tổng kết</h2>
<p>Ở bài viết này, mình đã phân tích ý tưởng load balancing grpc, có 2 điều cần hiểu rõ để tránh mơ hồ trong lúc hiện thực các phương pháp này:</p>
<ul>
<li><code>connection-based load balancing:</code> chia tải từng connection đến từng backend server, những connection này có tính chất <code>long-lived</code>.</li>
<li><code>request-based load balancing:</code> chia tải từng request đến từng connection, có thể hiểu chia tải ở tầng ứng dụng.</li>
</ul>
<p>Có nhiều phương pháp để hiện thực các ý tưởng này trong các hệ thống thực tế, ở các bài tiếp theo, mình sẽ đi vào hiện thực chúng để làm rõ hơn phần lý thuyết này.</p>

      <div class='other-tags'><b>Tags:</b> <a class='topic-tag' href='/tags/networking.html'>networking</a><a class='topic-tag' href='/tags/gRPC.html'>gRPC</a></div>
      <!-- <div class="copyright">
                Bạn được toàn quyền chia sẻ, trích dẫn hoặc copy, post lại, nhưng vui lòng ghi rõ nguồn, tác giả và không làm thay đổi nội dung bài viết. Nếu không làm vậy, thì OK, cũng ko sao, sẽ có thiên lôi thay ta dòm ngó nhà ngươi. 😈
                </div> -->
    </div>
  </div>
  <div class="footer">
    <p>Created with <i class="em em-coffee"></i> <a href="http://github.com/huytd/ristretto-rs">ristretto.rs</a></p>
    <div class="social">
      <a target="_blank" href="https://github.com/dangngoctam00"><i class="icon-github-squared"></i></a>
      <a target="_blank" href="https://www.linkedin.com/in/dang-ngoc-tam/"><i class="icon-linkedin-squared"></i></a>
    </div>
  </div>
  <script type="text/javascript" async=""
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
    </script>
  <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
          tex2jax: {
            inlineMath: [['$','$'], ['\\(','\\)']],
            skipTags: ["script","noscript","style","textarea", "code"],
            ignoreClass: ["comment", "comment-list"]
          }
        });
  </script>
</body>

</html>